{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from random import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# AutoML Libraries tpot and auto-sklearn\n",
    "from tpot import TPOTClassifier\n",
    "from autosklearn.classification import AutoSklearnClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulated Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated Annealing function steps\n",
    "# @parameters \n",
    "# sol - random solution (ML model)\n",
    "# X_train, y_train - training data\n",
    "# X_test, y_test - testing data\n",
    "# @return solution and cost\n",
    "\n",
    "# 1. Generate a random solution\n",
    "# 2. Calculate its cost using a cost function (accuracy of the ML Model)\n",
    "# 3. Generate a random neigboring solution\n",
    "# 4. Calculate new solutions cost (accuracy of the ML model)\n",
    "# 5. Compare solutions\n",
    "#     - If c_new > c_old move to the new solution\n",
    "#     - If c_new < c_old maybe move to the new solution\n",
    "# 6. Repeat steps until an acceptable solution is found or max number of iterations is reached\n",
    "def sa(sol, X_train, y_train, X_test, y_test):\n",
    "    t = 1.0\n",
    "    t_min = 0.00001\n",
    "    alpha = 0.9\n",
    "    old_cost = cost(sol, X_train, y_train, X_test, y_test)\n",
    "    while t > t_min:\n",
    "        i = 1\n",
    "        while i <= 100:\n",
    "            new_sol = neighbor(sol)\n",
    "            new_cost = cost(new_sol, X_train, y_train, X_test, y_test)\n",
    "            ap = acceptance_probability(old_cost, new_cost, t)\n",
    "            rnd = random()\n",
    "            # print(ap, rnd)\n",
    "            if ap > rnd:\n",
    "                sol = new_sol\n",
    "                old_cost = new_cost\n",
    "            i += 1\n",
    "        t = t * alpha\n",
    "    return sol, old_cost          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate neighboring solution\n",
    "# Solution is defined as a machine learning model along with a set of parameters\n",
    "# i.e.,\n",
    "# solution = {\n",
    "#     model: 'LinearRegression',\n",
    "#     parameters: {\n",
    "#         fit_intercept: true,\n",
    "#         normalize: true,\n",
    "#         copy_X: false,\n",
    "#         n_jobs: 4,\n",
    "#     }\n",
    "# }\n",
    "def neighbor(sol):\n",
    "    # Use the search_space to find a new neighbor of the current solution and return that\n",
    "    \n",
    "    # Chose a random parameter and modify it \n",
    "    parameter = choice(list(search_space[sol['name']].keys())) # random.choice()\n",
    "    # print('Selected parameter ', parameter)\n",
    "    \n",
    "    parameter_space = search_space[sol['name']][parameter]\n",
    "    # print('Parameter space', parameter_space)\n",
    "    \n",
    "    # Grab the random parameter from our current solution and change it\n",
    "    current_parameter_val = sol['parameters'][parameter]\n",
    "    # print('Current parameter value', current_parameter_val)\n",
    "    \n",
    "    # Grab the current index of the selected parameter of our model\n",
    "    current_index = parameter_space.index(current_parameter_val)\n",
    "    \n",
    "    # In one step modify the value of the selected parameter\n",
    "    if current_index == 0:\n",
    "        # index = 0 -> index++\n",
    "        modified_parameter = parameter_space[1];\n",
    "    elif current_index == len(parameter_space):\n",
    "        # index = length -> index--\n",
    "        modified_parameter = parameter_space[current_index - 1]\n",
    "    else: \n",
    "        # index = index + random(-1,1)\n",
    "        modified_parameter = parameter_space[(current_index + choice([-1, 1])) % len(parameter_space)]\n",
    "    \n",
    "    # Create a new solution copy the current one and replace the randomly chosen parameter\n",
    "    new_sol = sol\n",
    "    new_sol['parameters'][parameter] = modified_parameter\n",
    "    \n",
    "    # print('New parameter value', modified_parameter)\n",
    "    \n",
    "    # Return new neighboring solution\n",
    "    return new_sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return the cost of a current solution\n",
    "# In our case the cost is the accuracy (or we can use other metrics) of the current ML model / parameter configuration\n",
    "# TODO: RMSE or some other metric?\n",
    "def cost(sol, X_train, y_train, X_test, y_test): \n",
    "    # Get model\n",
    "    model = get_model(sol['name'], sol['parameters'])\n",
    "    \n",
    "    # Train model on data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    # predictions = model.predict(X_test)\n",
    "    \n",
    "    # Get accuracy or some other metric and return\n",
    "    score = model.score(X_test, y_test)\n",
    "    # print('Score: ', score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get a model with a parameter configuration\n",
    "def get_model(name, parameters):\n",
    "    # LogisticRegression\n",
    "    if name == 'LogisticRegression':\n",
    "        lr = LogisticRegression(**parameters)\n",
    "        return lr\n",
    "    # Model2\n",
    "    elif name == '':\n",
    "        return\n",
    "    # Model3\n",
    "    elif name == '':\n",
    "        return\n",
    "    # Model4\n",
    "    elif name == '':\n",
    "        return\n",
    "    # Model5\n",
    "    elif name == '':\n",
    "        return\n",
    "    # Default\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which recommends if we should jump to a new solutions or not\n",
    "# 1.0 - definitely switch\n",
    "# 0.0 - definitely stay put\n",
    "# 0.5 - 50/50 odds of switching\n",
    "# Usually calculated by e^((c_new - c_old)/t)\n",
    "\n",
    "def acceptance_probability(old_cost, new_cost, t): \n",
    "    if new_cost > old_cost:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return np.exp((new_cost - old_cost)/t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define 5 ML models\n",
    "\n",
    "# Search Space that will be used to define our neighborhood of ML models and hyperparameters\n",
    "# Basically our dictionary defining the model, its most important parameters, and their value ranges\n",
    "search_space = {\n",
    "    'LogisticRegression': {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C': np.logspace(-4, 4, 20).tolist(),\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "    },\n",
    "    'Model2': {\n",
    "        'property1': 'value_range',\n",
    "        'property2': 'value_range',\n",
    "        'property3': 'value_range',\n",
    "        'property4': 'value_range'\n",
    "    },\n",
    "    'Model3': {\n",
    "        'property1': 'value_range',\n",
    "        'property2': 'value_range',\n",
    "        'property3': 'value_range',\n",
    "        'property4': 'value_range'\n",
    "    },\n",
    "    'Model4': {\n",
    "        'property1': 'value_range',\n",
    "        'property2': 'value_range',\n",
    "        'property3': 'value_range',\n",
    "        'property4': 'value_range'\n",
    "    },\n",
    "    'Model5': {\n",
    "        'property1': 'value_range',\n",
    "        'property2': 'value_range',\n",
    "        'property3': 'value_range',\n",
    "        'property4': 'value_range'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define datasets\n",
    "\n",
    "# Iris\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some random solution that we will pass to the sa() to start with\n",
    "\n",
    "# LogisticRegression\n",
    "# Model2\n",
    "# Model3\n",
    "# Model4\n",
    "# Model5\n",
    "\n",
    "models = []\n",
    "\n",
    "models.append({\n",
    "    'name': 'LogisticRegression',\n",
    "    'parameters': {\n",
    "        'penalty': 'l2',\n",
    "        'C': 0.23357214690901212,\n",
    "        'solver': 'liblinear',\n",
    "        'n_jobs': -1\n",
    "    }\n",
    "})\n",
    "\n",
    "models.append({\n",
    "    'name': 'Model2',\n",
    "    'parameters': {\n",
    "        \n",
    "    }\n",
    "})\n",
    "\n",
    "models.append({\n",
    "    'name': 'Model3',\n",
    "    'parameters': {\n",
    "        \n",
    "    }\n",
    "})\n",
    "\n",
    "models.append({\n",
    "    'name': 'Model4',\n",
    "    'parameters': {\n",
    "        \n",
    "    }\n",
    "})\n",
    "\n",
    "models.append({\n",
    "    'name': 'Model5',\n",
    "    'parameters': {\n",
    "        \n",
    "    }\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best solution:  {'solution': 'x', 'score': 0.95}\n",
      "All solutions [{'solution': 'x', 'score': 0.5}, {'solution': 'x1', 'score': 0.55}, {'solution': 'x2', 'score': 0.15}, {'solution': 'x3', 'score': 0.95}, {'solution': 'x4', 'score': 0.75}, {'solution': 'x5', 'score': 0.25}]\n"
     ]
    }
   ],
   "source": [
    "# Save all solutions\n",
    "solutions = []\n",
    "\n",
    "# Save best solution\n",
    "best_solution = {\n",
    "    'solution': '',\n",
    "    'score': 0\n",
    "}\n",
    "\n",
    "# Iterate over models and get the best solution / score\n",
    "for i in models:\n",
    "    solution, score = sa(i, X_train, y_train, X_test, y_test)\n",
    "    solutions.append({\n",
    "       'solution': solution,\n",
    "       'score': score\n",
    "    })\n",
    "    \n",
    "    if score > best_solution['score']:\n",
    "        best_solution = {\n",
    "            'solution': solution,\n",
    "            'score': score\n",
    "        }\n",
    "    \n",
    "# Print results\n",
    "print('Best solution: ', best_solution)\n",
    "print('All solutions', solutions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n",
      "Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Get TPOT classification optimizer\n",
    "tpot_automl = TPOTClassifier(generations = 5, population_size = 20, cv = 5, random_state = 42, n_jobs = -1)\n",
    "\n",
    "# Fit on dataset\n",
    "tpot_automl.fit(X_train, y_train)\n",
    "\n",
    "# Get score\n",
    "print('Score: ', tpot_automl.score(X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING] [2020-01-22 14:27:20,242:EnsembleBuilder(1):ed217d05461c6dff1ebbcd34c23a0766] No models better than random - using Dummy Score!\n",
      "[WARNING] [2020-01-22 14:27:20,263:EnsembleBuilder(1):ed217d05461c6dff1ebbcd34c23a0766] No models better than random - using Dummy Score!\n",
      "Score:  0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "# Get auto-sklearn classifier\n",
    "sklearn_automl = AutoSklearnClassifier()\n",
    "\n",
    "# Fit on dataset\n",
    "sklearn_automl.fit(X_train, y_train)\n",
    "\n",
    "# y_hat = sklearn_automl.predict(X_test)\n",
    "\n",
    "# Get score\n",
    "print('Score: ', sklearn_automl.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
